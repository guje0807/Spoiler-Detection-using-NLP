{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e9c8157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import re,html,json\n",
    "import seaborn as sns\n",
    "import nltk as nt\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,classification_report\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a37d7786",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel(\"Cleaned_Data.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b209cb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Review', 'Title', 'Spoiler_flag', 'Synopsis',\n",
       "       'Cosine_Similarity', 'doc_similarity', 'tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2adf90ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"Unnamed: 0\",axis=1,inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1318e72c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12663\n",
       "1    10216\n",
       "Name: Spoiler_flag, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Spoiler_flag'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f88b9f14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review               1\n",
       "Title                0\n",
       "Spoiler_flag         0\n",
       "Synopsis             0\n",
       "Cosine_Similarity    0\n",
       "doc_similarity       0\n",
       "tokens               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b96aff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4a89321e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Review               0\n",
       "Title                0\n",
       "Spoiler_flag         0\n",
       "Synopsis             0\n",
       "Cosine_Similarity    0\n",
       "doc_similarity       0\n",
       "tokens               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0240f690",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[[\"Review\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b965cd45",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['Spoiler_flag']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b7cf32f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train,y_test = train_test_split(X,y,test_size=0.1,random_state=1)\n",
    "X_train_2, X_val, y_train_2, y_val = train_test_split(X_train,y_train,test_size=0.2,random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc0cefa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20590, 1)\n",
      "(20590,)\n",
      "(16472, 1)\n",
      "(16472,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_train_2.shape)\n",
    "print(y_train_2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1d5737ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37062, 1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pd.concat([X_train,X_train_2])\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "051527cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(37062,)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train = pd.concat([y_train,y_train_2])\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4e30029a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_model(x,y,val_x,val_y,model,vectorizer):\n",
    "    \n",
    "    #Training the model.\n",
    "    x_vectorized = vectorizer.fit_transform(x['Review'])\n",
    "    model.fit(x_vectorized,y)\n",
    "    \n",
    "    #Running on validation.\n",
    "    val_x_vectorized = vectorizer.transform(val_x['Review'])\n",
    "    Y_pred_val = model.predict(val_x_vectorized)\n",
    "    \n",
    "    print('Accuracy with the model {} is {} :'.format(type(model).__name__,accuracy_score(Y_pred_val,val_y)))\n",
    "    print(\"Classification Report is\")\n",
    "    print(classification_report(val_y,Y_pred_val))\n",
    "    \n",
    "    #Confusion Matrix \n",
    "    cm = confusion_matrix(y_val, Y_pred_val)\n",
    "    # Extract the false negatives count from the confusion matrix\n",
    "    false_negatives = cm[1, 0]\n",
    "\n",
    "    # Calculate the false negative ratio\n",
    "    false_neg_ratio = false_negatives / sum(cm[0])\n",
    "\n",
    "    # Print the false negative ratio\n",
    "    print(\"False negative ratio: \", false_neg_ratio)\n",
    "    \n",
    "    return model,vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece9ddc3",
   "metadata": {},
   "source": [
    "# Model Implementation with Count Vectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73acf95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "lr = LogisticRegression(max_iter=100,C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8211e14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noahr\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with the model LogisticRegression is 0.921321029626032 :\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.96      0.93      2243\n",
      "           1       0.95      0.88      0.91      1875\n",
      "\n",
      "    accuracy                           0.92      4118\n",
      "   macro avg       0.92      0.92      0.92      4118\n",
      "weighted avg       0.92      0.92      0.92      4118\n",
      "\n",
      "False negative ratio:  0.10254123941150245\n"
     ]
    }
   ],
   "source": [
    "lr_model,vectorizer = execute_model(X_train,y_train,X_val,y_val,lr,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "315744bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with the model SGDClassifier is 0.917921321029626 :\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.97      0.93      2243\n",
      "           1       0.96      0.85      0.90      1875\n",
      "\n",
      "    accuracy                           0.92      4118\n",
      "   macro avg       0.93      0.91      0.92      4118\n",
      "weighted avg       0.92      0.92      0.92      4118\n",
      "\n",
      "False negative ratio:  0.12394115024520731\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(loss='log_loss',max_iter=100)\n",
    "sgd_model,vectorizer = execute_model(X_train,y_train,X_val,y_val,sgd,cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73aa1dde",
   "metadata": {},
   "source": [
    "# Model Implementation with Tfid Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "892c7e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "tv = TfidfVectorizer(stop_words='english')\n",
    "lr = LogisticRegression(max_iter=100,C=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "085a554d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\noahr\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with the model LogisticRegression is 0.7948033025740651 :\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82      2243\n",
      "           1       0.81      0.71      0.76      1875\n",
      "\n",
      "    accuracy                           0.79      4118\n",
      "   macro avg       0.80      0.79      0.79      4118\n",
      "weighted avg       0.80      0.79      0.79      4118\n",
      "\n",
      "False negative ratio:  0.24164065983058403\n"
     ]
    }
   ],
   "source": [
    "lr_model,vectorizer = execute_model(X_train,y_train,X_val,y_val,lr,tv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "845ac519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with the model SGDClassifier is 0.7520641087906751 :\n",
      "Classification Report is\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.85      0.79      2243\n",
      "           1       0.78      0.64      0.70      1875\n",
      "\n",
      "    accuracy                           0.75      4118\n",
      "   macro avg       0.76      0.74      0.74      4118\n",
      "weighted avg       0.76      0.75      0.75      4118\n",
      "\n",
      "False negative ratio:  0.30450289790459206\n"
     ]
    }
   ],
   "source": [
    "sgd = SGDClassifier(loss='log_loss',max_iter=100)\n",
    "sgd_model,vectorizer = execute_model(X_train,y_train,X_val,y_val,sgd,tv)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdeca2b",
   "metadata": {},
   "source": [
    "# Grid Search On Count vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16ce2fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_grid_search(x,y,val_x,val_y,model,vectorizer):\n",
    "    print(type(model).__name__)\n",
    "    if type(model).__name__ == 'LogisticRegression':\n",
    "        \n",
    "        print(\"Model is {}\".format(type(model).__name__))\n",
    "        \n",
    "        param_grid_logistic = {'penalty' : ['l1', 'l2'],\n",
    "                               'C' : np.logspace(-4, 4, 20),\n",
    "                               'solver' : ['liblinear'],\n",
    "                               'max_iter' : [1000]}\n",
    "        clf = GridSearchCV(model,param_grid=param_grid_logistic,cv=5)\n",
    "        \n",
    "        #Training the model.\n",
    "        x_vectorized = vectorizer.fit_transform(x['Review'])\n",
    "        print('Running Grid Search')\n",
    "        best_fit = clf.fit(x_vectorized,y)\n",
    "        \n",
    "        print(\"best Params are:\",best_fit.best_params_)\n",
    "    \n",
    "        #Running on validation.\n",
    "        val_x_vectorized = vectorizer.transform(val_x['Review'])\n",
    "        Y_pred_val = best_fit.predict(val_x_vectorized)\n",
    "\n",
    "        print('Accuracy with the model {} is {} :'.format(type(model).__name__,accuracy_score(Y_pred_val,val_y)))\n",
    "        print(\"Classification Report is\")\n",
    "        print(classification_report(val_y,Y_pred_val))\n",
    "\n",
    "        #Confusion Matrix \n",
    "        cm = confusion_matrix(y_val, Y_pred_val)\n",
    "        # Extract the false negatives count from the confusion matrix\n",
    "        false_negatives = cm[1, 0]\n",
    "\n",
    "        # Calculate the false negative ratio\n",
    "        false_neg_ratio = false_negatives / sum(cm[0])\n",
    "\n",
    "        # Print the false negative ratio\n",
    "        print(\"False negative ratio: \", false_neg_ratio)\n",
    "\n",
    "        return best_fit,vectorizer\n",
    "    elif type(model).__name__ == 'SGDClassifier':\n",
    "        \n",
    "        print(\"Model is {}\".format(type(model).__name__))\n",
    "              \n",
    "        param_grid_sgd = [{'alpha' : [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3],\n",
    "                           'max_iter' : [1000],\n",
    "                           'loss': ['log'],\n",
    "                           'penalty': ['l2','l1']}]\n",
    "        \n",
    "        clf = GridSearchCV(model,param_grid=param_grid_logistic,cv=5)\n",
    "        \n",
    "        #Training the model.\n",
    "        x_vectorized = vectorizer.fit_transform(x['Review'])\n",
    "        print('Running Grid Search')\n",
    "        best_fit = clf.fit(x_vectorized,y)\n",
    "        \n",
    "        print(\"best Params are:\",best_fit.best_params_)\n",
    "        #Running on validation.\n",
    "        val_x_vectorized = vectorizer.transform(val_x['Review'])\n",
    "        Y_pred_val = best_fit.predict(val_x_vectorized)\n",
    "\n",
    "        print('Accuracy with the model {} is {} :'.format(type(model).__name__,accuracy_score(Y_pred_val,val_y)))\n",
    "        print(\"Classification Report is\")\n",
    "        print(classification_report(val_y,Y_pred_val))\n",
    "\n",
    "        #Confusion Matrix \n",
    "        cm = confusion_matrix(y_val, Y_pred_val)\n",
    "        # Extract the false negatives count from the confusion matrix\n",
    "        false_negatives = cm[1, 0]\n",
    "\n",
    "        # Calculate the false negative ratio\n",
    "        false_neg_ratio = false_negatives / sum(cm[0])\n",
    "\n",
    "        # Print the false negative ratio\n",
    "        print(\"False negative ratio: \", false_neg_ratio)\n",
    "\n",
    "        return best_fit,vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5aa6d2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(stop_words='english')\n",
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4222d80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "Model is LogisticRegression\n",
      "Running Grid Search\n"
     ]
    }
   ],
   "source": [
    "lr_model,vectorizer = execute_grid_search(X_train,y_train,X_val,y_val,lr,cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61964ec",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
